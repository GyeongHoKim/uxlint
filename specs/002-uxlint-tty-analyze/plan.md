# Implementation Plan: Real-time LLM Response Display in TTY Analyze Mode

**Branch**: `002-uxlint-tty-analyze` | **Date**: 2025-01-27 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-uxlint-tty-analyze/spec.md`

## Summary

TTY ëª¨ë“œì—ì„œ ë¶„ì„ ì¤‘ **ì§ì „ LLM ì‘ë‹µ(text + tool calls)ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ UIì— í‘œì‹œ**í•˜ê³ , LLM í˜¸ì¶œ ëŒ€ê¸° ì¤‘ì—ëŠ” **ìœ ë¨¸ëŸ¬ìŠ¤í•œ í´ë°± UI + ì• ë‹ˆë©”ì´ì…˜ ì•„ì´ì½˜**ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

### í•µì‹¬ ìš”êµ¬ì‚¬í•­ (Priority Order)
1. **ì§ì „ LLM Response í‘œì‹œ** (Primary): LLMì˜ í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ tool callsë¥¼ UIì— ì‹¤ì‹œê°„ í‘œì‹œ
2. **ìœ ë¨¸ëŸ¬ìŠ¤í•œ ëŒ€ê¸° ë©”ì‹œì§€ + ì• ë‹ˆë©”ì´ì…˜** (Secondary): ì •ìƒ ì‘ë™ ì¤‘ì„ì„ ì•Œë¦¬ëŠ” í´ë°± UI

í˜„ì¬ `generateText` ê¸°ë°˜ì˜ blocking UIë¥¼ ìœ ì§€í•˜ë©´ì„œ, ê° iterationë§ˆë‹¤ LLM ì‘ë‹µì„ UIì— ì „ë‹¬í•©ë‹ˆë‹¤. ì´ëŠ” [AI SDK Manual Agent Loop íŒ¨í„´](https://ai-sdk.dev/cookbook/node/manual-agent-loop)ì„ ë”°ë¥´ë©° ê¸°ì¡´ ì•„í‚¤í…ì²˜ë¥¼ ìµœì†Œí•œìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.

## Technical Context

**Language/Version**: TypeScript 5.x with ES modules
**Primary Dependencies**: React (Ink), AI SDK (`ai` package), XState
**Storage**: N/A (in-memory state only)
**Testing**: Ava + ink-testing-library + MockLanguageModelV2 from `ai/test`
**Target Platform**: Node.js >=18.18.0 (CLI application)
**Project Type**: Single project (CLI tool)
**Performance Goals**: UI ì—…ë°ì´íŠ¸ 1ì´ˆ ì´ë‚´, ì´ˆë‹¹ 5ê°œ ë©”ì‹œì§€ê¹Œì§€ ë°˜ì‘ì„± ìœ ì§€
**Constraints**: ê¸°ì¡´ Manual Agent Loop íŒ¨í„´ ìœ ì§€, `generateText` blocking ë°©ì‹ ìœ ì§€
**Scale/Scope**: ë‹¨ì¼ ì‚¬ìš©ì CLI ë„êµ¬

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

Verify compliance with uxlint Constitution v1.2.0:

**I. Code Quality Gates** (NON-NEGOTIABLE):
- [x] `npm run compile && npm run format && npm run lint` sequence will be run after all code changes
- [x] No linting bypasses (`// eslint-disable-next-line`) planned

**II. Test-First Development** (NON-NEGOTIABLE):
- [x] Tests will be written BEFORE implementation
- [x] Testing strategy defined: Unit tests (Ava) for models, visual regression (ink-testing-library) for components, mock-based tests for language model integrations
- [x] Language model tests use MockLanguageModelV2 from `ai/test`
- [x] 80% coverage target via c8

**III. UX Consistency**:
- [x] Feature references target personas from project context
- [x] Ink ecosystem libraries researched via GitHub MCP for UI patterns
- [x] Library choices documented with rationale (ink-spinner ìœ ì§€, ê¸°ì¡´ ì½”ë“œ ì¼ê´€ì„±)

**IV. Performance Accountability**:
- [x] Measurable performance goals defined (UI ì—…ë°ì´íŠ¸ 1ì´ˆ ì´ë‚´)
- [x] Baseline metrics identified (í˜„ì¬ iterationë‹¹ 1íšŒ onProgress í˜¸ì¶œ)

**V. Simplicity & Minimalism**:
- [x] Simplest viable approach chosen (ê¸°ì¡´ onProgress ì½œë°± í™•ì¥)
- [x] Any complexity justified in Complexity Tracking table below

## Project Structure

### Documentation (this feature)

```
specs/002-uxlint-tty-analyze/
â”œâ”€â”€ plan.md              # This file
â”œâ”€â”€ research.md          # Phase 0 output - completed
â”œâ”€â”€ data-model.md        # Phase 1 output - completed
â”œâ”€â”€ quickstart.md        # Phase 1 output - completed
â”œâ”€â”€ contracts/           # Phase 1 output - completed
â”‚   â”œâ”€â”€ llm-response-contract.ts      # LLM ì‘ë‹µ íƒ€ì… ê³„ì•½
â”‚   â”œâ”€â”€ analysis-state-contract.ts    # ë¶„ì„ ìƒíƒœ ê³„ì•½
â”‚   â””â”€â”€ waiting-messages-contract.ts  # ëŒ€ê¸° ë©”ì‹œì§€ ê³„ì•½
â””â”€â”€ tasks.md             # Phase 2 output (/speckit.tasks command)
```

### Source Code (repository root)

```
source/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ analysis.ts            # MODIFY: Add LLM response fields to AnalysisState
â”‚   â””â”€â”€ llm-response.ts        # NEW: LLM response type definitions
â”œâ”€â”€ constants/
â”‚   â””â”€â”€ waiting-messages.ts    # NEW: Waiting messages collection
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ use-analysis.ts        # MODIFY: Handle LLM response in state updates
â”œâ”€â”€ services/
â”‚   â””â”€â”€ ai-service.ts          # MODIFY: Pass LLM response via callback
â””â”€â”€ components/
    â”œâ”€â”€ analysis-progress.tsx      # MODIFY: Display LLM response + waiting message
    â”œâ”€â”€ analysis-runner.tsx        # MODIFY: Pass new props
    â””â”€â”€ llm-response-display.tsx   # NEW: LLM response display component

tests/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ llm-response.spec.ts       # NEW: LLM response type tests
â”œâ”€â”€ constants/
â”‚   â””â”€â”€ waiting-messages.spec.ts   # NEW: Waiting messages tests
â””â”€â”€ components/
    â”œâ”€â”€ llm-response-display.spec.tsx  # NEW: LLM response display tests
    â””â”€â”€ analysis-progress.spec.tsx     # MODIFY: Visual regression tests
```

**Structure Decision**: Single project structure maintained. New `models/llm-response.ts` and `components/llm-response-display.tsx` added for LLM response handling.

## Complexity Tracking

*No violations - simplest approach chosen*

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| N/A | N/A | N/A |

## Implementation Approach

### Phase 1: Data Model & Contracts âœ…

1. **LLMResponseData Type**: LLM ì‘ë‹µ ë°ì´í„° êµ¬ì¡° ì •ì˜ (text, toolCalls, iteration, timestamp)
2. **AnalysisState Extension**: `lastLLMResponse`, `waitingMessage`, `isWaitingForLLM` í•„ë“œ ì¶”ê°€
3. **AnalysisProgressCallback Extension**: `llmResponse` íŒŒë¼ë¯¸í„° ì¶”ê°€
4. **WaitingMessagesModule**: ëŒ€ê¸° ë©”ì‹œì§€ ì»¬ë ‰ì…˜ ë° ëœë¤ ì„ íƒ í•¨ìˆ˜

### Phase 2: Implementation Tasks (for `/speckit.tasks`)

**Task 1: Create LLM Response Type**
- íŒŒì¼: `source/models/llm-response.ts`
- `LLMResponseData`, `LLMToolCall` íƒ€ì… ì •ì˜
- í…ŒìŠ¤íŠ¸: `tests/models/llm-response.spec.ts`

**Task 2: Create Waiting Messages Module**
- íŒŒì¼: `source/constants/waiting-messages.ts`
- ìœ ë¨¸ëŸ¬ìŠ¤í•œ ëŒ€ê¸° ë©”ì‹œì§€ 20ê°œ ì´ìƒ ì •ì˜
- `getRandomWaitingMessage()` í•¨ìˆ˜ êµ¬í˜„
- í…ŒìŠ¤íŠ¸: `tests/constants/waiting-messages.spec.ts`

**Task 3: Extend AnalysisState Type**
- íŒŒì¼: `source/models/analysis.ts`
- `lastLLMResponse`, `waitingMessage`, `isWaitingForLLM`, `currentIteration` í•„ë“œ ì¶”ê°€
- ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì—…ë°ì´íŠ¸

**Task 4: Update AIService**
- íŒŒì¼: `source/services/ai-service.ts`
- `AnalysisProgressCallback` íƒ€ì… í™•ì¥ (llmResponse íŒŒë¼ë¯¸í„°)
- `analyzePage` ë©”ì„œë“œì—ì„œ:
  - generateText í˜¸ì¶œ ì „: `onProgress('analyzing', waitingMessage, undefined)`
  - generateText í˜¸ì¶œ í›„: `onProgress('analyzing', undefined, llmResponse)`
- í…ŒìŠ¤íŠ¸: MockLanguageModelV2 ì‚¬ìš©

**Task 5: Update useAnalysis Hook**
- íŒŒì¼: `source/hooks/use-analysis.ts`
- `onProgress` ì½œë°±ì—ì„œ LLM ì‘ë‹µ ë° ëŒ€ê¸° ìƒíƒœ ì²˜ë¦¬
- ìƒíƒœ ì—…ë°ì´íŠ¸ ë¡œì§:
  - `llmResponse` ìˆìœ¼ë©´: `lastLLMResponse` ì„¤ì •, `isWaitingForLLM: false`
  - `llmResponse` ì—†ìœ¼ë©´: `waitingMessage` ì„¤ì •, `isWaitingForLLM: true`
- í…ŒìŠ¤íŠ¸: hook í…ŒìŠ¤íŠ¸ ì—…ë°ì´íŠ¸

**Task 6: Create LLMResponseDisplay Component**
- íŒŒì¼: `source/components/llm-response-display.tsx`
- LLM í…ìŠ¤íŠ¸ ì‘ë‹µ í‘œì‹œ (truncate 200ì)
- Tool calls ëª©ë¡ í‘œì‹œ (ìµœëŒ€ 5ê°œ)
- Iteration ë²ˆí˜¸ í‘œì‹œ
- í…ŒìŠ¤íŠ¸: ink-testing-library ì‹œê° íšŒê·€ í…ŒìŠ¤íŠ¸

**Task 7: Update AnalysisProgress Component**
- íŒŒì¼: `source/components/analysis-progress.tsx`
- `lastLLMResponse`, `waitingMessage`, `isWaitingForLLM` props ì¶”ê°€
- `LLMResponseDisplay` ì»´í¬ë„ŒíŠ¸ í†µí•©
- ëŒ€ê¸° ì¤‘ ìŠ¤í”¼ë„ˆ + ë©”ì‹œì§€ í‘œì‹œ
- í…ŒìŠ¤íŠ¸: ink-testing-library ì‹œê° íšŒê·€ í…ŒìŠ¤íŠ¸

**Task 8: Update AnalysisRunner Component**
- íŒŒì¼: `source/components/analysis-runner.tsx`
- ìƒˆë¡œìš´ propsë¥¼ `AnalysisProgress`ì— ì „ë‹¬
- í…ŒìŠ¤íŠ¸: í†µí•© í…ŒìŠ¤íŠ¸

## Key Design Decisions

### 1. ì§ì „ LLM Response í‘œì‹œ (Primary Feature)

**Decision**: ê° iteration í›„ `result.text`ì™€ `result.toolCalls`ë¥¼ UIì— í‘œì‹œ

**Rationale**:
- ì‚¬ìš©ì í•µì‹¬ ìš”êµ¬ì‚¬í•­: "LLMì´ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ì•Œê³  ì‹¶ë‹¤"
- `generateText` ê²°ê³¼ì—ì„œ ì§ì ‘ ë°ì´í„° ì¶”ì¶œ ê°€ëŠ¥
- ê¸°ì¡´ Manual Agent Loop íŒ¨í„´ ìœ ì§€

**Data Flow**:
```
generateText() â†’ result.text, result.toolCalls
                        â†“
              onProgress(stage, msg, llmResponse)
                        â†“
              useAnalysis â†’ AnalysisState.lastLLMResponse
                        â†“
              AnalysisProgress â†’ LLMResponseDisplay
```

### 2. ìœ ë¨¸ëŸ¬ìŠ¤í•œ ëŒ€ê¸° ë©”ì‹œì§€ (Secondary Feature)

**Decision**: LLM í˜¸ì¶œ ì „ ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë©”ì‹œì§€ í‘œì‹œ, ì‘ë‹µ í›„ ì‹¤ì œ ì‘ë‹µìœ¼ë¡œ êµì²´

**Rationale**:
- ì •ìƒ ì‘ë™ ì¤‘ì„ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
- `generateText` blocking ë™ì•ˆ ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
- ìŠ¤í”¼ë„ˆ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ì§„í–‰ ì¤‘ì„ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ

### 3. generateText ìœ ì§€ vs streamText ì „í™˜

**Decision**: `generateText` ìœ ì§€

**Rationale**:
- í˜„ì¬ Manual Agent Loop íŒ¨í„´ê³¼ í˜¸í™˜ì„± ìœ ì§€
- `streamText` ì „í™˜ ì‹œ tool call ì²˜ë¦¬ ë¡œì§ ì¬ì„¤ê³„ í•„ìš”
- í•µì‹¬ ìš”êµ¬ì‚¬í•­ì€ "ì§ì „ ì‘ë‹µ í‘œì‹œ"ì´ë©° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹˜
- [AI SDK Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop) íŒ¨í„´ ì¤€ìˆ˜

### 4. ì½œë°± í™•ì¥ ë°©ì‹

**Decision**: ê¸°ì¡´ `AnalysisProgressCallback`ì— `llmResponse` íŒŒë¼ë¯¸í„° ì¶”ê°€

**Rationale**:
- ìµœì†Œ ë³€ê²½ ì›ì¹™
- ê¸°ì¡´ í˜¸ì¶œ ì½”ë“œì™€ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ (optional íŒŒë¼ë¯¸í„°)
- ë³„ë„ ì½œë°± ì¶”ê°€ ëŒ€ë¹„ ë³µì¡ë„ ê°ì†Œ

### 5. ë©”ì‹œì§€ Truncation

**Decision**: í…ìŠ¤íŠ¸ 200ì, tool calls 5ê°œë¡œ ì œí•œ

**Rationale**:
- í„°ë¯¸ë„ UI ê³µê°„ ì œí•œ
- ì‚¬ìš©ìëŠ” ìš”ì•½ë§Œ í•„ìš”
- ìƒì„¸ ë‚´ìš©ì€ ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì—ì„œ í™•ì¸ ê°€ëŠ¥

## UI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â³ Analyzing with AI                                            â”‚
â”‚ Page 1/3                                                        â”‚
â”‚ https://example.com/dashboard                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ ğŸ“ LLM Response (Iteration 3):                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ "I'm analyzing the navigation menu for accessibility        â”‚ â”‚
â”‚ â”‚ issues. The contrast ratio between the text and background  â”‚ â”‚
â”‚ â”‚ appears to be below WCAG AA standards..."                   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚ ğŸ”§ Tool Calls:                                                  â”‚
â”‚ â€¢ browser_snapshot                                              â”‚
â”‚ â€¢ addFinding (severity: high, category: accessibility)          â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â³ ğŸ¤” AI is pondering the mysteries of your UI...              â”‚
â”‚ (Shown only when waiting for next LLM response)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## References

- [AI SDK Manual Agent Loop](https://ai-sdk.dev/cookbook/node/manual-agent-loop)
- [AI SDK Stream Text with Chat Prompt](https://ai-sdk.dev/cookbook/next/stream-text-with-chat-prompt)
- [Ink Documentation](https://github.com/vadimdemedes/ink)
- [Ink UI Components](https://github.com/vadimdemedes/ink-ui)
- Constitution v1.2.0
